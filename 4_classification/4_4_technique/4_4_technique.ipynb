{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romihi/python_image_recognition/blob/main/4_classification/4_4_technique/4_4_technique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pythonで学ぶ画像認識　第4章 画像分類\n",
        "##第4.4節 精度向上のテクニック"
      ],
      "metadata": {
        "id": "OPBPVFpNAeDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###モジュールのインポートとGoogleドライブのマウント"
      ],
      "metadata": {
        "id": "acAhFxfZAnpN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "23QSwONJAamj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ed113c-82f7-484b-e5a6-41833e7c0db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from collections import deque\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Googleドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/python_image_recognition/4_classification/4_4_technique')\n",
        "\n",
        "import util\n",
        "import eval\n",
        "from model import BasicBlock"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ResNet18の実装"
      ],
      "metadata": {
        "id": "03w2_qQcB7NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    '''\n",
        "    ResNet18モデル\n",
        "    num_classes: 分類対象の物体クラス数\n",
        "    '''\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2,\n",
        "                               padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=3,\n",
        "                                     stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(64, 64),\n",
        "            BasicBlock(64, 64),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(64, 128, stride=2),\n",
        "            BasicBlock(128, 128),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(128, 256, stride=2),\n",
        "            BasicBlock(256, 256),\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            BasicBlock(256, 512, stride=2),\n",
        "            BasicBlock(512, 512),\n",
        "        )\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # ドロップアウトの追加\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    '''\n",
        "    パラメータの初期化関数\n",
        "    '''\n",
        "    def _reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # Heらが提案した正規分布を使って初期化\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_in\",\n",
        "                                        nonlinearity=\"relu\")\n",
        "\n",
        "    '''\n",
        "    順伝播関数\n",
        "    x           : 入力, [バッチサイズ, 入力チャネル数, 高さ, 幅]\n",
        "    return_embed: 特徴量を返すかロジットを返すかを選択する真偽値\n",
        "    '''\n",
        "    def forward(self, x: torch.Tensor, return_embed: bool=False):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.flatten(1)\n",
        "\n",
        "        if return_embed:\n",
        "            return x\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    '''\n",
        "    モデルパラメータが保持されているデバイスを返す関数\n",
        "    '''\n",
        "    def get_device(self):\n",
        "        return self.linear.weight.device\n",
        "\n",
        "    '''\n",
        "    モデルを複製して返す関数\n",
        "    '''\n",
        "    def copy(self):\n",
        "        return copy.deepcopy(self)"
      ],
      "metadata": {
        "id": "MQ541GbuB8-F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###学習・評価におけるハイパーパラメータやオプションの設定"
      ],
      "metadata": {
        "id": "XPYgbht4Cxol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    '''\n",
        "    ハイパーパラメータとオプションの設定\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.val_ratio = 0.2   # 検証に使う学習セット内のデータの割合\n",
        "        self.num_epochs = 30   # 学習エポック数\n",
        "        self.lr_drop = 25      # 学習率を減衰させるエポック\n",
        "        self.lr = 1e-2         # 学習率\n",
        "        self.moving_avg = 20   # 移動平均で計算する損失と正確度の値の数\n",
        "        self.batch_size = 32   # バッチサイズ\n",
        "        self.num_workers = 2   # データローダに使うCPUプロセスの数\n",
        "        self.device = 'cuda'   # 学習に使うデバイス\n",
        "        self.num_samples = 200 # t-SNEでプロットするサンプル数"
      ],
      "metadata": {
        "id": "9xchfU8mCycy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###学習・評価を行う関数"
      ],
      "metadata": {
        "id": "z42CA9ZyC5O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval():\n",
        "    config = Config()\n",
        "\n",
        "    # 入力データ正規化のために学習セットのデータを使って\n",
        "    # 各チャネルの平均と標準偏差を計算\n",
        "    dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=True, download=True,\n",
        "        transform=T.ToTensor())\n",
        "    channel_mean, channel_std = util.get_dataset_statistics(dataset)\n",
        "\n",
        "    # 画像の整形を行うクラスのインスタンスを用意\n",
        "    train_transforms = T.Compose((\n",
        "        T.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=channel_mean, std=channel_std),\n",
        "    ))\n",
        "    test_transforms = T.Compose((\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=channel_mean, std=channel_std),\n",
        "    ))\n",
        "\n",
        "    # 学習、評価セットの用意\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=True, download=True,\n",
        "        transform=train_transforms)\n",
        "    val_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=True, download=True,\n",
        "        transform=test_transforms)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=False, download=True,\n",
        "        transform=test_transforms)\n",
        "\n",
        "    # 学習・検証セットへ分割するためのインデックス集合の生成\n",
        "    val_set, train_set = util.generate_subset(\n",
        "        train_dataset, config.val_ratio)\n",
        "\n",
        "    print(f'学習セットのサンプル数　: {len(train_set)}')\n",
        "    print(f'検証セットのサンプル数　: {len(val_set)}')\n",
        "    print(f'テストセットのサンプル数: {len(test_dataset)}')\n",
        "\n",
        "    # インデックス集合から無作為にインデックスをサンプルするサンプラー\n",
        "    train_sampler = SubsetRandomSampler(train_set)\n",
        "\n",
        "    # DataLoaderを生成\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=config.batch_size,\n",
        "        num_workers=config.num_workers, sampler=train_sampler)\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=config.batch_size,\n",
        "        num_workers=config.num_workers, sampler=val_set)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=config.batch_size,\n",
        "        num_workers=config.num_workers)\n",
        "\n",
        "    # 目的関数の生成\n",
        "    loss_func = F.cross_entropy\n",
        "\n",
        "    # 検証セットの結果による最良モデルの保存用変数\n",
        "    val_loss_best = float('inf')\n",
        "    model_best = None\n",
        "\n",
        "    # ResNet18モデルの生成\n",
        "    model = ResNet18(len(train_dataset.classes))\n",
        "\n",
        "    # モデルを指定デバイスに転送(デフォルトはGPU)\n",
        "    model.to(config.device)\n",
        "\n",
        "    # 最適化器の生成\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.lr,\n",
        "                          momentum=0.9, weight_decay=1e-5)\n",
        "\n",
        "    # 学習率減衰を管理するスケジューラの生成\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer, milestones=[config.lr_drop], gamma=0.1)\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        with tqdm(train_loader) as pbar:\n",
        "            pbar.set_description(f'[エポック {epoch + 1}]')\n",
        "\n",
        "            # 移動平均計算用\n",
        "            losses = deque()\n",
        "            accs = deque()\n",
        "            for x, y in pbar:\n",
        "                # データをモデルと同じデバイスに転送\n",
        "                x = x.to(model.get_device())\n",
        "                y = y.to(model.get_device())\n",
        "\n",
        "                # パラメータの勾配をリセット\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝播\n",
        "                y_pred = model(x)\n",
        "\n",
        "                # 学習データに対する損失と正確度を計算\n",
        "                loss = loss_func(y_pred, y)\n",
        "                accuracy = (y_pred.argmax(dim=1) == \\\n",
        "                            y).float().mean()\n",
        "\n",
        "                # 誤差逆伝播\n",
        "                loss.backward()\n",
        "\n",
        "                # パラメータの更新\n",
        "                optimizer.step()\n",
        "\n",
        "                # 移動平均を計算して表示\n",
        "                losses.append(loss.item())\n",
        "                accs.append(accuracy.item())\n",
        "                if len(losses) > config.moving_avg:\n",
        "                    losses.popleft()\n",
        "                    accs.popleft()\n",
        "                pbar.set_postfix({\n",
        "                    'loss': torch.Tensor(losses).mean().item(),\n",
        "                    'accuracy': torch.Tensor(accs).mean().item()})\n",
        "\n",
        "        # 検証セットを使って精度評価\n",
        "        val_loss, val_accuracy = eval.evaluate(\n",
        "            val_loader, model, loss_func)\n",
        "        print(f'検証　: loss = {val_loss:.3f}, '\n",
        "                f'accuracy = {val_accuracy:.3f}')\n",
        "\n",
        "        # より良い検証結果が得られた場合、モデルを記録\n",
        "        if val_loss < val_loss_best:\n",
        "            val_loss_best = val_loss\n",
        "            model_best = model.copy()\n",
        "\n",
        "        # エポック終了時にスケジューラを更新\n",
        "        scheduler.step()\n",
        "\n",
        "    # テスト\n",
        "    test_loss, test_accuracy = eval.evaluate(\n",
        "        test_loader, model_best, loss_func)\n",
        "    print(f'テスト: loss = {test_loss:.3f}, '\n",
        "          f'accuracy = {test_accuracy:.3f}')\n",
        "\n",
        "    # t-SNEを使って特徴量の分布をプロット\n",
        "    util.plot_t_sne(test_loader, model_best, config.num_samples)\n",
        "\n",
        "    # モデルパラメータを保存\n",
        "    torch.save(model_best.state_dict(), 'resnet18.pth')"
      ],
      "metadata": {
        "id": "oWfa11AdC6H6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###学習・評価の実行"
      ],
      "metadata": {
        "id": "31DM2v6aC_09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w_B-y4BDCPi",
        "outputId": "be0272ec-81a6-40fa-e1e4-18c06a45b68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49081304.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "学習セットのサンプル数　: 40000\n",
            "検証セットのサンプル数　: 10000\n",
            "テストセットのサンプル数: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 1]: 100%|██████████| 1250/1250 [00:45<00:00, 27.21it/s, loss=1.91, accuracy=0.356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.621, accuracy = 0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 2]: 100%|██████████| 1250/1250 [00:41<00:00, 30.47it/s, loss=1.48, accuracy=0.495]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.408, accuracy = 0.525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 3]: 100%|██████████| 1250/1250 [00:43<00:00, 28.64it/s, loss=1.34, accuracy=0.536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.298, accuracy = 0.580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 4]: 100%|██████████| 1250/1250 [00:42<00:00, 29.61it/s, loss=1.26, accuracy=0.541]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.123, accuracy = 0.622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 5]: 100%|██████████| 1250/1250 [00:42<00:00, 29.08it/s, loss=1.06, accuracy=0.627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検証　: loss = 1.004, accuracy = 0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[エポック 6]:   8%|▊         | 96/1250 [00:05<01:01, 18.71it/s, loss=1.08, accuracy=0.614]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###デモ関数"
      ],
      "metadata": {
        "id": "2ZoTe2T0Jz-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def demo():\n",
        "    config = Config()\n",
        "\n",
        "    # 入力データ正規化のために学習セットのデータを使って\n",
        "    # 各チャネルの平均と標準偏差を計算\n",
        "    dataset = torchvision.datasets.CIFAR10(\n",
        "        root='data', train=True, download=True,\n",
        "        transform=T.ToTensor())\n",
        "    channel_mean, channel_std = util.get_dataset_statistics(dataset)\n",
        "\n",
        "    transforms = T.Compose((\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=channel_mean, std=channel_std),\n",
        "    ))\n",
        "\n",
        "    # ResNet18モデルの生成とパラメータの読み込み\n",
        "    model = ResNet18(len(dataset.classes))\n",
        "    model.load_state_dict(torch.load('resnet18.pth'))\n",
        "\n",
        "    # モデルを指定デバイスに転送(デフォルトはGPU)\n",
        "    model.to(config.device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for img_path in Path(\n",
        "        'drive/MyDrive/data/classification').glob('*.jpg'):\n",
        "        img = Image.open(img_path)\n",
        "        display(img.resize((256, 256)))\n",
        "\n",
        "        # 画像を整形\n",
        "        img = transforms(img)\n",
        "\n",
        "        # バッチ軸の追加\n",
        "        img = img.unsqueeze(0)\n",
        "\n",
        "        img = img.to(config.device)\n",
        "\n",
        "        pred = model(img)\n",
        "\n",
        "        # 数字表現の予測クラスラベルを取得\n",
        "        pred = pred[0].argmax()\n",
        "\n",
        "        print(f'予測: {dataset.classes[pred]}, 正解: {img_path.stem}')"
      ],
      "metadata": {
        "id": "IniAQsLXJ2g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###デモの実行"
      ],
      "metadata": {
        "id": "ikdu5fTnLoRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo()"
      ],
      "metadata": {
        "id": "csHAfE5XLqNF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}